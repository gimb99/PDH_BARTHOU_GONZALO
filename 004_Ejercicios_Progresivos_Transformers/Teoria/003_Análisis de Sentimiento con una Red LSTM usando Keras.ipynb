{"cells":[{"cell_type":"markdown","id":"cell-0","metadata":{"id":"cell-0"},"source":["# Análisis de Sentimiento con una Red LSTM usando Keras\n","\n","## Objetivo\n","\n","En esta actividad vas a construir un modelo de red neuronal recurrente (RNN), específicamente una LSTM, usando la API Keras de TensorFlow. El modelo va a leer frases en español y clasificar su sentimiento como positivo o negativo.\n","\n","### ¿Qué vamos a lograr?\n","\n","- Entender cómo las redes recurrentes procesan secuencias de palabras\n","- Implementar una LSTM que recuerda el contexto de la frase\n","- Usar embeddings de palabras para representar el significado\n","- Observar cómo las LSTM superan las limitaciones de bag-of-words\n","\n","### ¿Qué es una LSTM?\n","\n","LSTM (Long Short-Term Memory) es un tipo especial de red neuronal recurrente diseñada para:\n","- **Procesar secuencias**: Lee las palabras en orden, una después de la otra\n","- **Mantener memoria**: Recuerda información importante de palabras anteriores\n","- **Olvidar información irrelevante**: Decide qué información del pasado mantener y qué descartar\n","\n","A diferencia de las MLP que vimos antes, las LSTM **sí consideran el orden** de las palabras, lo cual es fundamental para entender el lenguaje."]},{"cell_type":"markdown","id":"cell-1","metadata":{"id":"cell-1"},"source":["## 1. Preparación del entorno\n","\n","Importamos las librerías necesarias, incluyendo herramientas de Keras para procesamiento de secuencias."]},{"cell_type":"code","execution_count":1,"id":"cell-2","metadata":{"id":"cell-2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760484177439,"user_tz":180,"elapsed":7394,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"e1359fac-7ec8-4025-a0e2-fb2e6b1c81a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow/Keras versión: 3.10.0\n"]}],"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","print(f\"TensorFlow/Keras versión: {keras.__version__}\")"]},{"cell_type":"markdown","id":"cell-3","metadata":{"id":"cell-3"},"source":["## 2. Datos de entrenamiento\n","\n","Vamos a usar las mismas frases que en la actividad anterior, pero ahora las vamos a procesar como **secuencias de palabras**, no como bolsa de palabras.\n","\n","Esta diferencia es fundamental: la LSTM va a poder aprovechar el orden en que aparecen las palabras."]},{"cell_type":"code","execution_count":2,"id":"cell-4","metadata":{"id":"cell-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760484185469,"user_tz":180,"elapsed":15,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"5edeae83-a3ae-4091-b85a-371ade2f1c9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total de frases: 10\n","Balance: 5 positivas, 5 negativas\n","\n","Ejemplos:\n","  1. 'La verdad, este lugar está bárbaro. Muy recomendab...' → Positivo\n","  2. 'Una porquería de servicio, nunca más vuelvo...' → Negativo\n","  3. 'Me encantó la comida, aunque la música estaba muy ...' → Positivo\n"]}],"source":["frases = [\n","    \"La verdad, este lugar está bárbaro. Muy recomendable\",\n","    \"Una porquería de servicio, nunca más vuelvo\",\n","    \"Me encantó la comida, aunque la música estaba muy fuerte\",\n","    \"El envío fue lento y el producto llegó dañado. Qué desastre\",\n","    \"Todo excelente. Atención de diez\",\n","    \"Qué estafa, me arrepiento de haber comprado\",\n","    \"Muy conforme con el resultado final\",\n","    \"No me gustó para nada la experiencia\",\n","    \"Superó mis expectativas, gracias\",\n","    \"No lo recomiendo, mala calidad\"\n","]\n","\n","etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n","\n","print(f\"Total de frases: {len(frases)}\")\n","print(f\"Balance: {sum(etiquetas)} positivas, {len(etiquetas) - sum(etiquetas)} negativas\\n\")\n","print(\"Ejemplos:\")\n","for i in range(3):\n","    sentimiento = \"Positivo\" if etiquetas[i] == 1 else \"Negativo\"\n","    print(f\"  {i+1}. '{frases[i][:50]}...' → {sentimiento}\")"]},{"cell_type":"markdown","id":"cell-5","metadata":{"id":"cell-5"},"source":["## 3. Tokenización y construcción del vocabulario\n","\n","Con Keras, vamos a convertir las frases en secuencias de números, donde cada número representa una palabra del vocabulario.\n","\n","### Diferencia clave con bag-of-words:\n","\n","**Bag-of-words:**\n","- \"Me gusta\" → [1, 0, 1, 0, 0] (solo presencia/ausencia)\n","\n","**Secuencia:**\n","- \"Me gusta\" → [5, 12] (orden preservado, cada palabra tiene un ID)"]},{"cell_type":"code","execution_count":3,"id":"cell-6","metadata":{"id":"cell-6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760484203799,"user_tz":180,"elapsed":16,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"3cc1e2d4-2a86-48d7-eff2-777d5fdce141"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño del vocabulario: 59 palabras únicas\n","\n","Primeras 15 palabras del vocabulario:\n","  '<OOV>' → 1\n","  'la' → 2\n","  'muy' → 3\n","  'de' → 4\n","  'me' → 5\n","  'el' → 6\n","  'qué' → 7\n","  'no' → 8\n","  'verdad' → 9\n","  'este' → 10\n","  'lugar' → 11\n","  'está' → 12\n","  'bárbaro' → 13\n","  'recomendable' → 14\n","  'una' → 15\n","\n","Ejemplo de conversión:\n","Frase original: 'La verdad, este lugar está bárbaro. Muy recomendable'\n","Secuencia numérica: [2, 9, 10, 11, 12, 13, 3, 14]\n"]}],"source":["# Tokenización: convierte palabras a números\n","tokenizer = Tokenizer(oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(frases)\n","\n","# Mostramos el vocabulario construido\n","vocab_size = len(tokenizer.word_index) + 1  # +1 por el índice 0\n","print(f\"Tamaño del vocabulario: {vocab_size} palabras únicas\\n\")\n","print(\"Primeras 15 palabras del vocabulario:\")\n","for palabra, idx in list(tokenizer.word_index.items())[:15]:\n","    print(f\"  '{palabra}' → {idx}\")\n","\n","# Convertimos frases a secuencias numéricas\n","secuencias = tokenizer.texts_to_sequences(frases)\n","\n","print(f\"\\nEjemplo de conversión:\")\n","print(f\"Frase original: '{frases[0]}'\")\n","print(f\"Secuencia numérica: {secuencias[0]}\")"]},{"cell_type":"markdown","id":"cell-7","metadata":{"id":"cell-7"},"source":["## 4. Padding: estandarizando la longitud de las secuencias\n","\n","Las redes neuronales necesitan entradas de tamaño fijo, pero nuestras frases tienen longitudes diferentes.\n","\n","**Solución: Padding**\n","- Rellenamos las secuencias cortas con ceros al final\n","- Todas las secuencias terminan con la misma longitud\n","\n","Ejemplo:\n","- `[5, 12]` → `[5, 12, 0, 0, 0]` (padding='post')"]},{"cell_type":"code","execution_count":4,"id":"cell-8","metadata":{"id":"cell-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760484317873,"user_tz":180,"elapsed":16,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"5adad8da-e99a-44dd-9307-b2ca7facb886"},"outputs":[{"output_type":"stream","name":"stdout","text":["Longitud de la frase más larga: 11 palabras\n","\n","Forma de X después del padding: (10, 11)\n","  10 frases × 11 posiciones\n","\n","Ejemplo de secuencia con padding:\n","Frase: 'La verdad, este lugar está bárbaro. Muy recomendable'\n","Secuencia: [ 2  9 10 11 12 13  3 14  0  0  0]\n","Nota: Los ceros al final son padding (relleno)\n"]}],"source":["# Calculamos la longitud máxima\n","maxlen = max(len(seq) for seq in secuencias)\n","print(f\"Longitud de la frase más larga: {maxlen} palabras\\n\")\n","\n","# Aplicamos padding\n","X = pad_sequences(secuencias, maxlen=maxlen, padding='post')\n","y = np.array(etiquetas)\n","\n","print(f\"Forma de X después del padding: {X.shape}\")\n","print(f\"  {X.shape[0]} frases × {X.shape[1]} posiciones\\n\")\n","\n","print(\"Ejemplo de secuencia con padding:\")\n","print(f\"Frase: '{frases[0]}'\")\n","print(f\"Secuencia: {X[0]}\")\n","print(f\"Nota: Los ceros al final son padding (relleno)\")"]},{"cell_type":"markdown","id":"cell-9","metadata":{"id":"cell-9"},"source":["## 5. Definición del modelo LSTM\n","\n","Vamos a construir una red con tres componentes clave:\n","\n","### 1. Capa de Embedding\n","Convierte cada palabra (número) en un vector denso de dimensión fija. Estos vectores se aprenden durante el entrenamiento y capturan similitudes semánticas.\n","\n","**Ejemplo conceptual:**\n","- \"excelente\" → [0.8, 0.9, -0.1, 0.7, ...]\n","- \"bueno\" → [0.7, 0.8, -0.2, 0.6, ...] (vector similar)\n","- \"malo\" → [-0.7, -0.8, 0.2, -0.6, ...] (vector opuesto)\n","\n","### 2. Capa LSTM\n","Procesa la secuencia de embeddings manteniendo memoria del contexto.\n","\n","### 3. Capa Dense (salida)\n","Clasifica el sentimiento basándose en la representación aprendida por la LSTM."]},{"cell_type":"code","execution_count":5,"id":"cell-10","metadata":{"id":"cell-10","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1760484453630,"user_tz":180,"elapsed":221,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"0f49f6f4-aecf-44ac-f1c6-c3be196d9507"},"outputs":[{"output_type":"stream","name":"stdout","text":["Arquitectura del modelo:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │           \u001b[38;5;34m944\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │         \u001b[38;5;34m6,272\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │            \u001b[38;5;34m33\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">944</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,249\u001b[0m (28.32 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,249</span> (28.32 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,249\u001b[0m (28.32 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,249</span> (28.32 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Parámetros totales: 7,249\n"]}],"source":["# Parámetros del modelo\n","embedding_dim = 16  # Dimensión de los vectores de embeddings\n","lstm_units = 32     # Número de unidades en la capa LSTM\n","\n","# Construcción del modelo\n","modelo = Sequential([\n","    # Capa 1: Embedding - convierte palabras a vectores densos\n","    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n","\n","    # Capa 2: LSTM - procesa la secuencia con memoria\n","    LSTM(units=lstm_units),\n","\n","    # Capa 3: Dense - clasificación final\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compilación del modelo\n","modelo.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")\n","\n","# Construir el modelo explícitamente\n","modelo.build(input_shape=X.shape)\n","\n","print(\"Arquitectura del modelo:\")\n","modelo.summary()\n","\n","print(f\"\\nParámetros totales: {modelo.count_params():,}\")"]},{"cell_type":"markdown","id":"cell-11","metadata":{"id":"cell-11"},"source":["## 6. Entrenamiento\n","\n","Entrenamos el modelo por varias épocas. La LSTM va a aprender:\n","- Qué palabras son importantes para el sentimiento\n","- Cómo el orden afecta el significado\n","- Qué patrones secuenciales indican positivo o negativo"]},{"cell_type":"code","execution_count":8,"id":"cell-12","metadata":{"id":"cell-12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760484876172,"user_tz":180,"elapsed":3379,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"45e0e3a9-d689-4b95-a652-f6f93ba54b62"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","INICIANDO ENTRENAMIENTO\n","============================================================\n","Épocas: 20\n","Batch size: 2\n","\n","Epoch 1/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0280\n","Epoch 2/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0267\n","Epoch 3/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0242\n","Epoch 4/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0218\n","Epoch 5/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0204 \n","Epoch 6/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0196\n","Epoch 7/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0188\n","Epoch 8/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0178\n","Epoch 9/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0172\n","Epoch 10/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0160\n","Epoch 11/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0153\n","Epoch 12/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0144\n","Epoch 13/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0136\n","Epoch 14/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0132\n","Epoch 15/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0126\n","Epoch 16/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0122\n","Epoch 17/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0115\n","Epoch 18/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0111\n","Epoch 19/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0106\n","Epoch 20/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0102\n","Epoch 21/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0099\n","Epoch 22/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0098\n","Epoch 23/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0095\n","Epoch 24/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0088\n","Epoch 25/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0084\n","Epoch 26/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0083\n","Epoch 27/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0081\n","Epoch 28/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0081\n","Epoch 29/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0074\n","Epoch 30/30\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0074\n","\n","============================================================\n","ENTRENAMIENTO FINALIZADO\n","============================================================\n"]}],"source":["print(\"=\"*60)\n","print(\"INICIANDO ENTRENAMIENTO\")\n","print(\"=\"*60)\n","print(f\"Épocas: 20\")\n","print(f\"Batch size: 2\\n\")\n","\n","# Entrenamiento\n","history = modelo.fit(\n","    X, y,\n","    epochs=30,\n","    batch_size=4,\n","    verbose=1\n",")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"ENTRENAMIENTO FINALIZADO\")\n","print(\"=\"*60)"]},{"cell_type":"markdown","id":"cell-13","metadata":{"id":"cell-13"},"source":["## 7. Análisis del entrenamiento\n","\n","Observá cómo evolucionan la pérdida (loss) y la precisión (accuracy) durante el entrenamiento.\n","\n","- **Loss decrece**: El modelo comete menos errores\n","- **Accuracy aumenta**: Más predicciones correctas\n","\n","Si la accuracy llega a 1.0, significa que el modelo clasificó perfectamente todos los ejemplos de entrenamiento."]},{"cell_type":"markdown","id":"cell-14","metadata":{"id":"cell-14"},"source":["## 8. Evaluación con frases nuevas\n","\n","Ahora vamos a probar el modelo con frases que no vio durante el entrenamiento. Esta es la verdadera prueba de si aprendió patrones generalizables."]},{"cell_type":"code","execution_count":14,"id":"cell-15","metadata":{"id":"cell-15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760485049763,"user_tz":180,"elapsed":99,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"716f8c5a-04d2-4f8e-8935-872858691094"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","EVALUACIÓN EN FRASES NUEVAS\n","============================================================\n","\n","Frase 1: 'Muy buena atención, quedé encantado'\n","  Predicción: Positivo (probabilidad: 0.99)\n","  Confianza: Alta\n","\n","Frase 2: 'Horrible experiencia, no vuelvo más'\n","  Predicción: Negativo (probabilidad: 0.01)\n","  Confianza: Alta\n","\n","Frase 3: 'Todo excelente, gracias por la atención'\n","  Predicción: Positivo (probabilidad: 0.99)\n","  Confianza: Alta\n","\n","Frase 4: 'Me arrepiento completamente, fue un desastre'\n","  Predicción: Negativo (probabilidad: 0.01)\n","  Confianza: Alta\n","\n","Frase 5: 'horrible atención'\n","  Predicción: Positivo (probabilidad: 0.99)\n","  Confianza: Alta\n","\n","============================================================\n"]}],"source":["frases_nuevas = [\n","    \"Muy buena atención, quedé encantado\",\n","    \"Horrible experiencia, no vuelvo más\",\n","    \"Todo excelente, gracias por la atención\",\n","    \"Me arrepiento completamente, fue un desastre\",\n","    \"horrible atención\"\n","]\n","\n","print(\"=\"*60)\n","print(\"EVALUACIÓN EN FRASES NUEVAS\")\n","print(\"=\"*60)\n","\n","# Tokenizamos y aplicamos padding\n","secuencias_nuevas = tokenizer.texts_to_sequences(frases_nuevas)\n","X_nuevo = pad_sequences(secuencias_nuevas, maxlen=maxlen, padding='post')\n","\n","# Predicción\n","predicciones = modelo.predict(X_nuevo, verbose=0)\n","\n","# Mostrar resultados\n","for i, (frase, pred) in enumerate(zip(frases_nuevas, predicciones), 1):\n","    probabilidad = pred[0]\n","    clase = \"Positivo\" if probabilidad >= 0.5 else \"Negativo\"\n","\n","    print(f\"\\nFrase {i}: '{frase}'\")\n","    print(f\"  Predicción: {clase} (probabilidad: {probabilidad:.2f})\")\n","\n","    # Indicador de confianza\n","    if probabilidad >= 0.8 or probabilidad <= 0.2:\n","        print(f\"  Confianza: Alta\")\n","    elif probabilidad >= 0.6 or probabilidad <= 0.4:\n","        print(f\"  Confianza: Media\")\n","    else:\n","        print(f\"  Confianza: Baja (ambiguo)\")\n","\n","print(\"\\n\" + \"=\"*60)"]},{"cell_type":"markdown","id":"cell-16","metadata":{"id":"cell-16"},"source":["## 9. Comparación con enfoques anteriores\n","\n","Recapitulemos lo que mejoramos con cada modelo:\n","\n","### Perceptrón simple:\n","- ✗ No considera orden de palabras\n","- ✗ Representación binaria (0/1)\n","- ✗ Modelo lineal\n","- ✓ Muy simple de entender\n","\n","### MLP (Red Multicapa):\n","- ✗ No considera orden de palabras\n","- ✗ Representación binaria (0/1)\n","- ✓ Puede aprender patrones no lineales\n","- ✓ Mejor capacidad de generalización\n","\n","### LSTM:\n","- ✓ **Considera el orden de las palabras**\n","- ✓ **Embeddings aprendidos** (vectores densos)\n","- ✓ **Memoria del contexto** (puede recordar palabras anteriores)\n","- ✓ Puede aprender patrones no lineales complejos\n","\n","La LSTM es un avance significativo porque finalmente podemos procesar el lenguaje como una secuencia, no como una bolsa desordenada de palabras."]},{"cell_type":"markdown","id":"cell-17","metadata":{"id":"cell-17"},"source":["## 10. Reflexión final\n","\n","### ¿Qué aprendimos?\n","\n","1. **Procesamiento de secuencias**: Las LSTM pueden leer frases palabra por palabra, manteniendo memoria del contexto.\n","\n","2. **Embeddings de palabras**: En lugar de vectores binarios (0/1), cada palabra se representa con un vector denso que captura su significado.\n","\n","3. **Orden importa**: \"No me gusta\" y \"Me gusta, no\" ahora se procesan diferente (antes eran idénticos con bag-of-words).\n","\n","4. **Tokenización automática**: Keras construye el vocabulario automáticamente y maneja palabras desconocidas con `<OOV>`.\n","\n","### Ventajas sobre MLP con bag-of-words:\n","\n","- Captura el orden de las palabras\n","- Aprende representaciones semánticas (embeddings)\n","- Puede detectar patrones secuenciales\n","- Mejor manejo de frases largas\n","\n","### Limitaciones que aún persisten:\n","\n","1. **Procesamiento secuencial**: La LSTM lee de izquierda a derecha, puede \"olvidar\" información del principio en frases muy largas\n","\n","2. **No puede mirar hacia adelante**: Al procesar una palabra, no sabe qué viene después\n","\n","3. **Dataset pequeño**: Con solo 10 ejemplos, los embeddings no se entrenan bien\n","\n","4. **Vocabulario limitado**: Solo conoce las palabras que aparecieron en el entrenamiento\n","\n","### ¿Qué sigue?\n","\n","En la próxima actividad vamos a ver cómo los **modelos preentrenados** como BETO (BERT en español) resuelven muchas de estas limitaciones:\n","\n","- Ya fueron entrenados con millones de textos\n","- Tienen embeddings muy ricos\n","- Usan arquitectura Transformer (no secuencial, con **atención**)\n","- Pueden hacer análisis de sentimiento sin necesidad de entrenar desde cero\n","\n","Esto nos va a llevar al concepto de **transfer learning**, que revolucionó el NLP y es la base de los LLMs modernos como GPT."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}