{"cells":[{"cell_type":"markdown","id":"cell-0","metadata":{"id":"cell-0"},"source":["# Clasificación de Sentimientos con una Red Neuronal Multicapa (MLP)\n","\n","## Objetivo\n","\n","En esta actividad vas a construir una red neuronal feedforward multicapa (MLP) usando PyTorch. El objetivo es entrenarla para que pueda clasificar frases en español como positivas o negativas.\n","\n","### Con esto vas a:\n","\n","- Comprender cómo se construye una red con múltiples capas y neuronas\n","- Usar funciones de activación no lineales (ReLU, Sigmoid)\n","- Implementar entrenamiento automático con optimizadores modernos\n","- Observar cómo una MLP mejora respecto al perceptrón simple del laboratorio anterior\n","\n","### ¿Qué es una red neuronal multicapa?\n","\n","A diferencia del perceptrón simple (una sola neurona), una MLP tiene:\n","- **Capa de entrada**: Recibe los features del texto\n","- **Capas ocultas**: Una o más capas intermedias que aprenden representaciones complejas\n","- **Capa de salida**: Produce la predicción final\n","\n","Las capas ocultas permiten aprender patrones **no lineales**, lo que le da mucha más capacidad expresiva al modelo."]},{"cell_type":"markdown","id":"cell-1","metadata":{"id":"cell-1"},"source":["## 1. Preparación del entorno\n","\n","Importamos PyTorch y NumPy para comenzar."]},{"cell_type":"code","execution_count":1,"id":"cell-2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-2","executionInfo":{"status":"ok","timestamp":1760483484389,"user_tz":180,"elapsed":8792,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"0395fd2f-4248-4444-c781-f716a8db258f"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch versión: 2.8.0+cu126\n","Device disponible: CPU\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","print(f\"PyTorch versión: {torch.__version__}\")\n","print(f\"Device disponible: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"]},{"cell_type":"markdown","id":"cell-3","metadata":{"id":"cell-3"},"source":["## 2. Datos de entrenamiento\n","\n","Usamos un conjunto más grande de frases típicas de opiniones escritas en Argentina, etiquetadas como positivas (1) o negativas (0).\n","\n","Vamos a incluir casos más variados y complejos que en el laboratorio anterior."]},{"cell_type":"code","execution_count":2,"id":"cell-4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-4","executionInfo":{"status":"ok","timestamp":1760483510596,"user_tz":180,"elapsed":15,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"1137a987-262f-4be1-fc6e-02d6c2fbe8ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total de frases: 10\n","Balance: 5 positivas, 5 negativas\n","\n","Ejemplos:\n","  1. 'La verdad, este lugar está bárbaro. Muy recomendable' → Positivo\n","  2. 'Una porquería de servicio, nunca más vuelvo' → Negativo\n","  3. 'Me encantó la comida, aunque la música estaba muy fuerte' → Positivo\n"]}],"source":["frases = [\n","    \"La verdad, este lugar está bárbaro. Muy recomendable\",\n","    \"Una porquería de servicio, nunca más vuelvo\",\n","    \"Me encantó la comida, aunque la música estaba muy fuerte\",\n","    \"El envío fue lento y el producto llegó dañado. Qué desastre\",\n","    \"Todo excelente. Atención de diez\",\n","    \"Qué estafa, me arrepiento de haber comprado\",\n","    \"Muy conforme con el resultado final\",\n","    \"No me gustó para nada la experiencia\",\n","    \"Superó mis expectativas, gracias\",\n","    \"No lo recomiendo, mala calidad\"\n","]\n","\n","etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])  # 1 = Positivo, 0 = Negativo\n","\n","print(f\"Total de frases: {len(frases)}\")\n","print(f\"Balance: {sum(etiquetas)} positivas, {len(etiquetas) - sum(etiquetas)} negativas\\n\")\n","print(\"Ejemplos:\")\n","for i in range(3):\n","    sentimiento = \"Positivo\" if etiquetas[i] == 1 else \"Negativo\"\n","    print(f\"  {i+1}. '{frases[i]}' → {sentimiento}\")"]},{"cell_type":"markdown","id":"cell-5","metadata":{"id":"cell-5"},"source":["## 3. Construcción del vocabulario\n","\n","Definimos manualmente un vocabulario con palabras que suelen aparecer en frases de opinión con carga positiva o negativa.\n","\n","En este caso expandimos el vocabulario para cubrir más términos comunes."]},{"cell_type":"code","execution_count":3,"id":"cell-6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-6","executionInfo":{"status":"ok","timestamp":1760483532423,"user_tz":180,"elapsed":14,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"23b70938-ca6b-4549-f8cc-1c1edbb85e8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulario: 16 palabras clave\n","\n","Palabras: ['bárbaro', 'recomendable', 'porquería', 'nunca', 'encantó', 'fuerte', 'desastre', 'excelente', 'estafa', 'arrepiento', 'conforme', 'gustó', 'superó', 'gracias', 'recomiendo', 'mala']\n"]}],"source":["vocabulario = [\n","    \"bárbaro\", \"recomendable\", \"porquería\", \"nunca\", \"encantó\",\n","    \"fuerte\", \"desastre\", \"excelente\", \"estafa\", \"arrepiento\",\n","    \"conforme\", \"gustó\", \"superó\", \"gracias\", \"recomiendo\", \"mala\"\n","]\n","\n","print(f\"Vocabulario: {len(vocabulario)} palabras clave\")\n","print(f\"\\nPalabras: {vocabulario}\")"]},{"cell_type":"markdown","id":"cell-7","metadata":{"id":"cell-7"},"source":["## 4. Preprocesamiento: vectorización de las frases\n","\n","Seguimos usando bag-of-words como en el laboratorio anterior: cada frase se convierte en un vector binario que indica si contiene alguna de las palabras del vocabulario.\n","\n","Luego convertimos estos vectores a tensores de PyTorch para poder usarlos con redes neuronales."]},{"cell_type":"code","execution_count":4,"id":"cell-8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-8","executionInfo":{"status":"ok","timestamp":1760483540073,"user_tz":180,"elapsed":117,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"80dae58f-4f1d-4eed-c799-ee09a6782158"},"outputs":[{"output_type":"stream","name":"stdout","text":["Datos preprocesados:\n","  X shape: torch.Size([10, 16]) (frases × features)\n","  y shape: torch.Size([10, 1]) (frases × 1)\n","\n","Primera frase vectorizada: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Etiqueta: 1.0\n"]}],"source":["def vectorizar(frase, vocabulario):\n","    \"\"\"\n","    Convierte una frase en un vector binario según el vocabulario.\n","\n","    Args:\n","        frase: String con la frase a vectorizar\n","        vocabulario: Lista de palabras clave\n","\n","    Returns:\n","        Array de numpy con 1s y 0s (float32 para PyTorch)\n","    \"\"\"\n","    tokens = frase.lower().split()\n","    return np.array([1 if palabra in tokens else 0 for palabra in vocabulario], dtype=np.float32)\n","\n","# Vectorizamos todas las frases\n","X_np = np.array([vectorizar(frase, vocabulario) for frase in frases], dtype=np.float32)\n","y_np = etiquetas.astype(np.float32).reshape(-1, 1)\n","\n","# Convertimos a tensores de PyTorch\n","X = torch.tensor(X_np)\n","y = torch.tensor(y_np)\n","\n","print(\"Datos preprocesados:\")\n","print(f\"  X shape: {X.shape} (frases × features)\")\n","print(f\"  y shape: {y.shape} (frases × 1)\")\n","print(f\"\\nPrimera frase vectorizada: {X[0]}\")\n","print(f\"Etiqueta: {y[0].item()}\")"]},{"cell_type":"markdown","id":"cell-9","metadata":{"id":"cell-9"},"source":["## 5. Definición del modelo MLP\n","\n","Vamos a crear un modelo simple con:\n","- **Capa de entrada**: Tamaño = cantidad de palabras en el vocabulario\n","- **Capa oculta**: 8 neuronas con activación ReLU\n","- **Capa de salida**: 1 neurona con activación Sigmoid (para clasificación binaria)\n","\n","### ¿Por qué estas activaciones?\n","\n","- **ReLU** (Rectified Linear Unit): `f(x) = max(0, x)` → Introduce no linealidad, permite aprender patrones complejos\n","- **Sigmoid**: `f(x) = 1 / (1 + e^(-x))` → Convierte la salida a un valor entre 0 y 1 (probabilidad)"]},{"cell_type":"code","execution_count":5,"id":"cell-10","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-10","executionInfo":{"status":"ok","timestamp":1760483643102,"user_tz":180,"elapsed":27,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"fd07302c-be02-4125-8eb2-285a115f2fe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Arquitectura del modelo:\n","MLP(\n","  (net): Sequential(\n","    (0): Linear(in_features=16, out_features=8, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=8, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","\n","Parámetros totales: 145\n"]}],"source":["input_size = len(vocabulario)\n","hidden_size = 8\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        # Definimos la arquitectura secuencial\n","        self.net = nn.Sequential(\n","            nn.Linear(input_size, hidden_size),  # Capa oculta\n","            nn.ReLU(),                            # Activación no lineal\n","            nn.Linear(hidden_size, 1),            # Capa de salida\n","            nn.Sigmoid()                          # Activación para clasificación binaria\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"Propagación hacia adelante (forward pass)\"\"\"\n","        return self.net(x)\n","\n","# Creamos una instancia del modelo\n","modelo = MLP()\n","\n","print(\"Arquitectura del modelo:\")\n","print(modelo)\n","print(f\"\\nParámetros totales: {sum(p.numel() for p in modelo.parameters())}\")"]},{"cell_type":"markdown","id":"cell-11","metadata":{"id":"cell-11"},"source":["## 6. Configuración del entrenamiento\n","\n","Necesitamos definir dos componentes clave:\n","\n","### Función de pérdida (Loss Function)\n","\n","Usamos **Binary Cross Entropy (BCE)**: mide qué tan diferentes son las predicciones del modelo de las etiquetas reales. El objetivo del entrenamiento es minimizar esta pérdida.\n","\n","Fórmula: `BCE = -[y·log(ŷ) + (1-y)·log(1-ŷ)]`\n","\n","### Optimizador\n","\n","Usamos **Adam**: un optimizador moderno que ajusta automáticamente la tasa de aprendizaje para cada parámetro. Es más eficiente que el ajuste manual que hicimos en el perceptrón."]},{"cell_type":"code","execution_count":6,"id":"cell-12","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-12","executionInfo":{"status":"ok","timestamp":1760483817388,"user_tz":180,"elapsed":6754,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"31b38e71-2bd0-4288-cb81-f7195155fbf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configuración de entrenamiento:\n","  Loss function: Binary Cross Entropy\n","  Optimizador: Adam\n","  Learning rate: 0.01\n"]}],"source":["# Función de pérdida\n","criterio = nn.BCELoss()  # Binary Cross Entropy Loss\n","\n","# Optimizador\n","optimizador = optim.Adam(modelo.parameters(), lr=0.01)\n","\n","print(\"Configuración de entrenamiento:\")\n","print(f\"  Loss function: Binary Cross Entropy\")\n","print(f\"  Optimizador: Adam\")\n","print(f\"  Learning rate: 0.01\")"]},{"cell_type":"markdown","id":"cell-13","metadata":{"id":"cell-13"},"source":["## 7. Entrenamiento del modelo\n","\n","Vamos a entrenar el modelo por varias épocas. En cada época:\n","1. Calculamos las predicciones (forward pass)\n","2. Calculamos la pérdida\n","3. Calculamos los gradientes (backpropagation)\n","4. Actualizamos los pesos (optimizer step)\n","\n","Este proceso es automático gracias a PyTorch, a diferencia del ajuste manual que hicimos en el perceptrón."]},{"cell_type":"code","execution_count":9,"id":"cell-14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-14","executionInfo":{"status":"ok","timestamp":1760483931746,"user_tz":180,"elapsed":66,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"f407dad7-f113-481c-e2a8-501838bdf1ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","INICIANDO ENTRENAMIENTO\n","============================================================\n","Épocas: 50\n","\n","Época  10, Pérdida: 0.0073\n","Época  20, Pérdida: 0.0066\n","Época  30, Pérdida: 0.0060\n","Época  40, Pérdida: 0.0055\n","Época  50, Pérdida: 0.0050\n","\n","============================================================\n","ENTRENAMIENTO FINALIZADO\n","============================================================\n"]}],"source":["epocas = 50\n","\n","print(\"=\"*60)\n","print(\"INICIANDO ENTRENAMIENTO\")\n","print(\"=\"*60)\n","print(f\"Épocas: {epocas}\\n\")\n","\n","for epoca in range(epocas):\n","    # Modo entrenamiento\n","    modelo.train()\n","\n","    # Forward pass: calculamos predicciones\n","    salida = modelo(X)\n","\n","    # Calculamos la pérdida\n","    loss = criterio(salida, y)\n","\n","    # Backpropagation: calculamos gradientes\n","    optimizador.zero_grad()  # Limpiamos gradientes previos\n","    loss.backward()           # Calculamos nuevos gradientes\n","\n","    # Actualizamos pesos\n","    optimizador.step()\n","\n","    # Mostramos progreso cada 10 épocas\n","    if (epoca + 1) % 10 == 0:\n","        print(f\"Época {epoca+1:3d}, Pérdida: {loss.item():.4f}\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"ENTRENAMIENTO FINALIZADO\")\n","print(\"=\"*60)"]},{"cell_type":"markdown","id":"cell-15","metadata":{"id":"cell-15"},"source":["## 8. Análisis del entrenamiento\n","\n","Observá cómo la pérdida disminuye con el tiempo. Esto indica que el modelo está aprendiendo a clasificar mejor las frases.\n","\n","Una pérdida cercana a 0 significa que el modelo está muy confiado en sus predicciones correctas."]},{"cell_type":"markdown","id":"cell-16","metadata":{"id":"cell-16"},"source":["## 9. Evaluación con frases nuevas\n","\n","Probamos la red con frases que no estaban en el entrenamiento, para ver cómo generaliza."]},{"cell_type":"code","execution_count":10,"id":"cell-17","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-17","executionInfo":{"status":"ok","timestamp":1760483940692,"user_tz":180,"elapsed":20,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"cc75327c-d156-4530-bd0c-1c82e12a0ef5"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","EVALUACIÓN EN FRASES NUEVAS\n","============================================================\n","\n","Frase 1: 'No me gustó la atención, bastante mala'\n","  Predicción: Negativo (probabilidad: 0.00)\n","  Confianza: Alta\n","\n","Frase 2: 'Muy buena experiencia, todo excelente'\n","  Predicción: Positivo (probabilidad: 0.97)\n","  Confianza: Alta\n","\n","Frase 3: 'Una estafa total, no lo recomiendo'\n","  Predicción: Positivo (probabilidad: 0.99)\n","  Confianza: Alta\n","\n","Frase 4: 'Súper conforme con el servicio'\n","  Predicción: Positivo (probabilidad: 1.00)\n","  Confianza: Alta\n","\n","Frase 5: 'Nada que ver con lo prometido, una decepción'\n","  Predicción: Positivo (probabilidad: 0.98)\n","  Confianza: Alta\n","\n","============================================================\n"]}],"source":["frases_prueba = [\n","    \"No me gustó la atención, bastante mala\",\n","    \"Muy buena experiencia, todo excelente\",\n","    \"Una estafa total, no lo recomiendo\",\n","    \"Súper conforme con el servicio\",\n","    \"Nada que ver con lo prometido, una decepción\"\n","]\n","\n","print(\"=\"*60)\n","print(\"EVALUACIÓN EN FRASES NUEVAS\")\n","print(\"=\"*60)\n","\n","# Vectorizamos las frases de prueba\n","X_prueba_np = np.array([vectorizar(frase, vocabulario) for frase in frases_prueba], dtype=np.float32)\n","X_prueba = torch.tensor(X_prueba_np)\n","\n","# Modo evaluación (desactiva dropout, batch norm, etc.)\n","modelo.eval()\n","\n","# Predicción sin calcular gradientes (más eficiente)\n","with torch.no_grad():\n","    predicciones = modelo(X_prueba)\n","\n","# Mostrar resultados\n","for i, (frase, pred) in enumerate(zip(frases_prueba, predicciones), 1):\n","    probabilidad = pred.item()\n","    clase = \"Positivo\" if probabilidad >= 0.5 else \"Negativo\"\n","    print(f\"\\nFrase {i}: '{frase}'\")\n","    print(f\"  Predicción: {clase} (probabilidad: {probabilidad:.2f})\")\n","\n","    # Indicador visual de confianza\n","    if probabilidad >= 0.8 or probabilidad <= 0.2:\n","        print(f\"  Confianza: Alta\")\n","    elif probabilidad >= 0.6 or probabilidad <= 0.4:\n","        print(f\"  Confianza: Media\")\n","    else:\n","        print(f\"  Confianza: Baja (ambiguo)\")\n","\n","print(\"\\n\" + \"=\"*60)"]},{"cell_type":"markdown","id":"cell-18","metadata":{"id":"cell-18"},"source":["## 10. Reflexión final\n","\n","### ¿Qué aprendimos?\n","\n","1. **Arquitectura multicapa**: Vimos cómo una red con capas ocultas puede aprender representaciones más complejas que un perceptrón simple.\n","\n","2. **Activaciones no lineales**: ReLU permite que la red aprenda patrones no lineales, algo imposible con un perceptrón simple.\n","\n","3. **Entrenamiento automático**: PyTorch maneja automáticamente el cálculo de gradientes (backpropagation) y la actualización de pesos, a diferencia del ajuste manual del perceptrón.\n","\n","4. **Probabilidades vs decisiones binarias**: La salida Sigmoid nos da una probabilidad (0-1) en lugar de solo 0 o 1, lo que permite medir la confianza del modelo.\n","\n","### Ventajas sobre el perceptrón simple\n","\n","- Puede aprender patrones más complejos (no lineales)\n","- Mejor capacidad de generalización\n","- Optimización más eficiente con Adam\n","- Salida probabilística (más informativa)\n","\n","### Limitaciones que aún persisten\n","\n","1. **No considera el orden de las palabras**: Bag-of-words sigue sin capturar secuencias\n","2. **Vocabulario fijo**: Solo conoce palabras predefinidas\n","3. **Sin contexto global**: Cada palabra se procesa independientemente\n","4. **Dataset pequeño**: Con solo 10 ejemplos, la generalización es limitada\n","\n","### ¿Qué sigue?\n","\n","En la próxima actividad vamos a ver cómo las **redes recurrentes (LSTM)** pueden procesar secuencias de palabras manteniendo memoria del contexto. Esto nos va a permitir:\n","\n","- Capturar el orden de las palabras\n","- Entender dependencias temporales\n","- Procesar frases de longitud variable\n","- Aprovechar embeddings de palabras\n","\n","Las LSTM son el paso previo a entender los Transformers, que revolucionaron el NLP."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}