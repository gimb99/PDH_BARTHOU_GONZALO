{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+CBGFYK0ZO1ZdyrGbJnO+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo Integrador Individual\n",
        "## \"De Texto Crudo a Insights: Pipeline Completo de An√°lisis de NLP\"\n",
        "\n",
        "**Fecha de entrega**: Jueves 25 de septiembre  \n",
        "**Modalidad**: Individual  \n",
        "**Formato**: Repositorio GitHub con notebook documentado\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "amw_uwocTntI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1: Construcci√≥n del Corpus\n"
      ],
      "metadata": {
        "id": "JZ_pqIoyT42y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intento de Corpus literario"
      ],
      "metadata": {
        "id": "sg7rPp55BPmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se han revisado varias fuentes posibles de informaci√≥n para cuentos contempor√°neos o de autores latinoamericanos pero encontr√© varios problemas a la hora de seleccionar el corpus de este formato que cumpla con el criterio minimo de volumen para procesarlo...\n",
        "\n",
        "#### Project Gutenberg\n",
        "Usando https://www.gutenberg.org/browse/languages/es\n",
        "\n",
        "Autor elegido: Blasco Ib√°√±ez, Vicente, 1867-1928\n",
        "\n",
        "No tenia suficiente volumen digerible para cuentos y las obras parec√≠an dispersas y repetidas\n",
        "\n",
        "No tuve forma de encontrar en una forma concisa autores argentinos o latinoamericanos que est√©n en Gutenberg y que dispongan de mucho material usable para el proyecto... Podria buscar a mano pero tardaria mucho\n",
        "\n",
        "Se intent√≥ recolectar datos con\n",
        "* Cuentos valencianos\n",
        "https://www.gutenberg.org/ebooks/66514\n",
        "\n",
        "* La condenada (cuentos)\n",
        "https://www.gutenberg.org/ebooks/27736\n",
        "\n",
        "* La Catedral\n",
        "\n",
        "Entre otros...\n",
        "\n",
        "#### Biblioteca Digital Argentina\n",
        "La p√°gina no se encuentra disponible, y las alternativas no son lo suficientemente voluminosas o contemporaneas para el target que se busca\n",
        "\n",
        "#### Cervantes Virtual\n",
        "Mayoritariamente autores espa√±oles, se buscaban autores latinoamericanos\n",
        "\n",
        "#### Ciudad Seva\n",
        "De algun modo no me convenci√≥ del todo, y prefer√≠ buscar otro tipo de corpus para entonces"
      ],
      "metadata": {
        "id": "h1sZbwoET_Ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corpus periodistico\n",
        "\n",
        "Se decide entonces recolectar informaci√≥n relacionada al tema *tecnolog√≠a*, con √©nfasis en el asunto de **privacidad**.\n",
        "\n",
        "Fuentes elegidas\n",
        "- https://derechodelared.com/\n",
        "- https://www.anred.org/\n",
        "- https://www.pagina12.com.ar/\n",
        "\n",
        "Se omiten otros sitios periodisticos como Clarin, La Naci√≥n e Infobae ya que no proporcionaban suficiente informaci√≥n relevante al filtro que queremos aplicar\n",
        "\n",
        "---\n",
        "\n",
        "Yapa - No usables pero interesantes para tener en RSS posiblemente?\n",
        "- https://www.elladodelmal.com/\n",
        "- (Listado con m√°s blogs y sitios periodisticos) https://www.genbeta.com/seguridad/17-expertos-blogs-y-newsletter-a-seguir-si-de-verdad-te-interesan-seguridad-y-privacidad"
      ],
      "metadata": {
        "id": "3Ze0kJtf-CTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resolucion"
      ],
      "metadata": {
        "id": "Xg1w8noXP-Xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import de librerias"
      ],
      "metadata": {
        "id": "ygcafj-aQBJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from urllib.parse import urlparse\n"
      ],
      "metadata": {
        "id": "raOUHOweP_zg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Obtenci√≥n de listado de URLs\n",
        "Las urls a probar de mi corpus est√°n guardadas en un .txt dentro del repositorio"
      ],
      "metadata": {
        "id": "GcunddFwn-tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 003_barthou-gonzalo-nlp-integrador/corpus/corpusList.txt\n",
        "# https://raw.githubusercontent.com/gimb99/PDH_BARTHOU_GONZALO/refs/heads/develop/003_barthou-gonzalo-nlp-integrador/corpus/corpusList.txt\n",
        "\n",
        "# URL cruda del archivo en GitHub\n",
        "github_txt_url = \"https://raw.githubusercontent.com/gimb99/PDH_BARTHOU_GONZALO/refs/heads/develop/003_barthou-gonzalo-nlp-integrador/corpus/corpusList.txt\"\n",
        "\n",
        "# Descargar y procesar las l√≠neas\n",
        "response = requests.get(github_txt_url)\n",
        "lines = response.text.splitlines()\n",
        "urls = [line.strip() for line in lines if line.strip()]\n"
      ],
      "metadata": {
        "id": "4vcNJmDbRRg9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Guardado de .txt como archivos raw"
      ],
      "metadata": {
        "id": "K-fO7fIUoGP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear carpeta para guardar los archivos\n",
        "folder = \"raw_texts\"\n",
        "os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# Funci√≥n para limpiar el nombre del archivo\n",
        "def clean_filename(title, index):\n",
        "    title = re.sub(r'[^\\w\\s-]', '', title).strip().replace(' ', '_')\n",
        "    return f\"{index:03d}_{title[:50]}.txt\"  # Limita el nombre a 50 caracteres\n",
        "\n",
        "# Recorrer las URLs\n",
        "for i, url in enumerate(urls, start=1):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Extraer t√≠tulo y texto (ajustar seg√∫n el sitio)\n",
        "        domain = urlparse(url).netloc\n",
        "        try:\n",
        "          if \"derechodelared.com\" in domain:\n",
        "              title = soup.find(\"h1\", class_=\"block-entry-title\").get_text(strip=True)\n",
        "          elif \"clarin.com\" in domain:\n",
        "              title = soup.find(\"h1\", class_=\"title\").get_text(strip=True)\n",
        "          else:\n",
        "              title = soup.find(\"h1\").get_text(strip=True)\n",
        "        except:\n",
        "          title = f\"articulo_{i}\"\n",
        "\n",
        "\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "        text = \"\\n\".join([p.get_text(strip=True) for p in paragraphs])\n",
        "\n",
        "        # Guardar como archivo .txt\n",
        "        filename = clean_filename(title, i)\n",
        "        filepath = os.path.join(folder, filename)\n",
        "\n",
        "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"URL: {url}\\n\")\n",
        "            f.write(f\"T√≠tulo: {title}\\n\\n\")\n",
        "            f.write(text)\n",
        "\n",
        "        print(f\"‚úÖ Guardado: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error con {url}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-zq56_Kn9GY",
        "outputId": "582cb481-8814-4194-e223-17e0ba5a95fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Guardado: 001_Tiktok_se_enfrenta_a_una_posible_multa_de_27_millo.txt\n",
            "‚úÖ Guardado: 002_Manzana_podrida_decenas_de_exesp√≠as_israel√≠es_fuer.txt\n",
            "‚úÖ Guardado: 003_El_auge_del_tecnofeudalismo.txt\n",
            "‚úÖ Guardado: 004_Qu√©_hay_detr√°s_de_las_colas_para_la_venta_de_iris.txt\n",
            "‚úÖ Guardado: 005_Sam_Altman_creador_de_ChatGPT_y_GPT-4_mi_peor_temo.txt\n",
            "‚úÖ Guardado: 006_Natalia_Zuazo_el_problema_es_cuando_el_avance_de_l.txt\n",
            "‚úÖ Guardado: 007_Espionaje_ilegal_del_Ministerio_de_Seguridad_porte.txt\n",
            "‚úÖ Guardado: 008_Pensamiento_cr√≠tico_De_verdad_sabemos_qu√©_hacemos_.txt\n",
            "‚úÖ Guardado: 009_CABA_la_Legislatura_porte√±a_debate_un_pol√©mico_pro.txt\n",
            "‚úÖ Guardado: 010_WhatsApp_no_cerrar√°_cuentas_pero_limitar√°_funcione.txt\n",
            "‚úÖ Guardado: 011_Polisis_una_IA_que_se_lee_las_pol√≠ticas_de_privaci.txt\n",
            "‚úÖ Guardado: 012_La_AEPD_presenta_nuevos_recursos_para_fomentar_la_.txt\n",
            "‚úÖ Guardado: 013_Chat_Control_el_plan_europeo_para_escanear_tus¬†men.txt\n",
            "‚úÖ Guardado: 014_La_NSA_compra_datos_de_navegaci√≥n_de_los_usuarios¬†.txt\n",
            "‚úÖ Guardado: 015_Microsoft_mantendr√°_en_la_UE_los_datos_personales_.txt\n",
            "‚úÖ Guardado: 016_Pandemia_de_control_digital.txt\n",
            "‚úÖ Guardado: 017_Una_pelea_por_los_datos_de_los_usuarios.txt\n",
            "‚úÖ Guardado: 018_La_hora_de_los_nuevos_derechos_y_algo_m√°s.txt\n",
            "‚úÖ Guardado: 019_Marcas_enfrentan_el_desaf√≠o_de_reforzar_la_conexi√≥.txt\n",
            "‚úÖ Guardado: 020_Bullrich_desatada_autoriz√≥_a_la_Polic√≠a_Federal_a_.txt\n",
            "‚úÖ Guardado: 021_Meta_enfrenta_sanciones_millonarias_en_Nigeria_por.txt\n",
            "‚úÖ Guardado: 022_Catamarca_y_Telecentro_firman_un_acuerdo_hist√≥rico.txt\n",
            "‚úÖ Guardado: 023_Apple_multada_Francia_sanciona_con_162_millones_po.txt\n",
            "‚úÖ Guardado: 024_C√≥mo_las_grandes_empresas_tech_lograron_meterse_en.txt\n",
            "‚úÖ Guardado: 025_Globalizaci√≥n_recargada_nuevos_nacionalismos_y_con.txt\n",
            "‚úÖ Guardado: 026_La_era_del_capitalismo_digital_magnates_tecnol√≥gic.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Textos debug / desarrollo - Ignorar"
      ],
      "metadata": {
        "id": "JC9tVrWEsN0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elminar carpeta para reintentar"
      ],
      "metadata": {
        "id": "jXAQu6YyxECV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar carpeta\n",
        "# folder = \"raw_texts\"  # Cambi√° por el nombre de tu carpeta\n",
        "\n",
        "# # Eliminar todos los archivos dentro de la carpeta\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path):\n",
        "#             os.remove(file_path)\n",
        "#             print(f\"üóëÔ∏è Borrado: {filename}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ùå Error con {filename}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "stz7QWy7sJqD",
        "outputId": "50a25753-cf54-4226-919c-7655bc225428"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üóëÔ∏è Borrado: 018_La_hora_de_los_nuevos_derechos_y_algo_m√°s.txt\n",
            "üóëÔ∏è Borrado: 011_Polisis_una_IA_que_se_lee_las_pol√≠ticas_de_privaci.txt\n",
            "üóëÔ∏è Borrado: 007_Espionaje_ilegal_del_Ministerio_de_Seguridad_porte.txt\n",
            "üóëÔ∏è Borrado: 023_Apple_multada_Francia_sanciona_con_162_millones_po.txt\n",
            "üóëÔ∏è Borrado: 017_Una_pelea_por_los_datos_de_los_usuarios.txt\n",
            "üóëÔ∏è Borrado: 016_Pandemia_de_control_digital.txt\n",
            "üóëÔ∏è Borrado: 026_La_era_del_capitalismo_digital_magnates_tecnol√≥gic.txt\n",
            "üóëÔ∏è Borrado: 003_El_auge_del_tecnofeudalismo.txt\n",
            "üóëÔ∏è Borrado: 024_C√≥mo_las_grandes_empresas_tech_lograron_meterse_en.txt\n",
            "üóëÔ∏è Borrado: 015_Microsoft_mantendr√°_en_la_UE_los_datos_personales_.txt\n",
            "üóëÔ∏è Borrado: 005_Sam_Altman_creador_de_ChatGPT_y_GPT-4_mi_peor_temo.txt\n",
            "üóëÔ∏è Borrado: 022_Catamarca_y_Telecentro_firman_un_acuerdo_hist√≥rico.txt\n",
            "üóëÔ∏è Borrado: 008_Pensamiento_cr√≠tico_De_verdad_sabemos_qu√©_hacemos_.txt\n",
            "üóëÔ∏è Borrado: 002_Manzana_podrida_decenas_de_exesp√≠as_israel√≠es_fuer.txt\n",
            "üóëÔ∏è Borrado: 021_Meta_enfrenta_sanciones_millonarias_en_Nigeria_por.txt\n",
            "üóëÔ∏è Borrado: 020_Bullrich_desatada_autoriz√≥_a_la_Polic√≠a_Federal_a_.txt\n",
            "üóëÔ∏è Borrado: 004_Qu√©_hay_detr√°s_de_las_colas_para_la_venta_de_iris.txt\n",
            "üóëÔ∏è Borrado: 014_La_NSA_compra_datos_de_navegaci√≥n_de_los_usuarios¬†.txt\n",
            "üóëÔ∏è Borrado: 013_Chat_Control_el_plan_europeo_para_escanear_tus¬†men.txt\n",
            "üóëÔ∏è Borrado: 019_Marcas_enfrentan_el_desaf√≠o_de_reforzar_la_conexi√≥.txt\n",
            "üóëÔ∏è Borrado: 025_Globalizaci√≥n_recargada_nuevos_nacionalismos_y_con.txt\n",
            "üóëÔ∏è Borrado: 006_Natalia_Zuazo_el_problema_es_cuando_el_avance_de_l.txt\n",
            "üóëÔ∏è Borrado: 012_La_AEPD_presenta_nuevos_recursos_para_fomentar_la_.txt\n",
            "üóëÔ∏è Borrado: 001_Tiktok_se_enfrenta_a_una_posible_multa_de_27_millo.txt\n",
            "üóëÔ∏è Borrado: 010_WhatsApp_no_cerrar√°_cuentas_pero_limitar√°_funcione.txt\n",
            "üóëÔ∏è Borrado: 009_CABA_la_Legislatura_porte√±a_debate_un_pol√©mico_pro.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardado de zip"
      ],
      "metadata": {
        "id": "y8DIdrUuxGyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardado de .zip para luego extraerlo y subirlo a github\n",
        "# shutil.make_archive(\"raw_texts\", \"zip\", \"raw_texts\")\n",
        "# files.download(\"raw_texts.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vZUjvefRpmyO",
        "outputId": "66119215-a2c5-4aa6-d33e-cb235c68fa96"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ee668ce-e960-4727-9b4a-44464c1acb8b\", \"raw_texts.zip\", 93508)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Guardado de metadata"
      ],
      "metadata": {
        "id": "7O55hrbXoafd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armado metadata.csv\n",
        "# Lista para guardar los metadatos\n",
        "metadata = []\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Ejemplo de extracci√≥n (puede variar seg√∫n el sitio)\n",
        "        title = soup.find(\"h1\").get_text(strip=True)\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "        text = \" \".join([p.get_text(strip=True) for p in paragraphs])\n",
        "\n",
        "        metadata.append({\n",
        "            \"url\": url,\n",
        "            \"title\": title,\n",
        "            \"text\": text[:500],  # Guardamos solo los primeros 500 caracteres\n",
        "            \"length\": len(text),\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error con {url}: {e}\")"
      ],
      "metadata": {
        "id": "9CxRQhkwm8LB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(metadata)\n",
        "df.to_csv(\"metadata.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "i2StCD7JnODG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Parte 2: An√°lisis T√©cnico - Estructura del Notebook\n"
      ],
      "metadata": {
        "id": "onmapu9NT5gI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lti5KrHSccTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datos de commiteo - Ignorar"
      ],
      "metadata": {
        "id": "epq5HxFWEbEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Para commits, guardar ruta como\n",
        "## 003_barthou-gonzalo-nlp-integrador/notebook/analisis_integrador.ipynb"
      ],
      "metadata": {
        "id": "lxwDTQr0EXru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}